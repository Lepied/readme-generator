// ============================================
// Gemini API Wrapper
// ============================================

import { ChatGoogleGenerativeAI } from '@langchain/google-genai';
import { CONFIG } from '../config/constants.js';

let modelInstance: ChatGoogleGenerativeAI | null = null;

export function initializeModel(apiKey: string, model?: string): void {
    const selectedModel = model || CONFIG.DEFAULT_MODEL;
    console.log(`ğŸ”§ [Init] ëª¨ë¸ ì´ˆê¸°í™”: ${selectedModel}`);
    
    modelInstance = new ChatGoogleGenerativeAI({
        apiKey,
        model: selectedModel,
        temperature: CONFIG.DEFAULT_TEMPERATURE,
        maxOutputTokens: CONFIG.MAX_OUTPUT_TOKENS,
    });
}

export function getModel(): ChatGoogleGenerativeAI {
    if (!modelInstance) {
        throw new Error('ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initializeModel()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.');
    }
    return modelInstance;
}

export async function generateWithRetry(
    prompt: string,
    retries: number = CONFIG.MAX_RETRIES
): Promise<string> {
    const model = getModel();
    
    for (let i = 0; i < retries; i++) {
        try {
            const response = await model.invoke(prompt);
            return response.content.toString();
        } catch (error: any) {
            console.error(`ì‹œë„ ${i + 1}/${retries} ì‹¤íŒ¨:`, error);
            
            if (i === retries - 1) throw error;
            
            await new Promise(resolve => setTimeout(resolve, CONFIG.RETRY_DELAY * (i + 1)));
        }
    }
    
    throw new Error('ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼');
}
