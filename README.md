# README Auto Generator

ìë™ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ README.md íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
Ollamaì™€ LangChainì„ í™œìš©í•˜ì—¬ AI ê¸°ë°˜ ë¬¸ì„œí™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ Quick Start

### 1. í•„ìš”í•œ ë„êµ¬ ì„¤ì¹˜

- Python 3.8 ì´ìƒ
- [Ollama](https://ollama.com/download)

### 2-A. Google Gemini API ì‚¬ìš© (ì¶”ì²œ! ë¬´ë£Œ ğŸ”¥)

**Gemini 2.0 Flash - 2025ë…„ ìµœì‹  ëª¨ë¸!**
- ğŸ”¥ Gemini 2.0 Flash - ê°€ì¥ ë¹ ë¥´ê³  ê°•ë ¥ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)
- âš¡ ë§¤ìš° ë¹ ë¦„ (Ollamaë³´ë‹¤ 5-10ë°°)
- ğŸ†“ ì™„ì „ ë¬´ë£Œ (ì›” 150ë§Œ í† í°, ë¶„ë‹¹ 1500íšŒ)
- ğŸš€ ì„¤ì¹˜ ë¶ˆí•„ìš”, ì¸í„°ë„·ë§Œ ìˆìœ¼ë©´ OK
- ğŸ§  ê°•ë ¥í•œ ì„±ëŠ¥ (GPT-4ê¸‰)

```bash
# 1. API í‚¤ ë¬´ë£Œ ë°›ê¸°: https://aistudio.google.com/apikey
#    (Google ê³„ì •ë§Œ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°œê¸‰)

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)
set GOOGLE_API_KEY=your_api_key

# ë˜ëŠ” .env íŒŒì¼ ìƒì„±
echo GOOGLE_API_KEY=your_api_key > .env
```

**ë¬´ë£Œ ì œí•œ:**
- ë¶„ë‹¹ 15íšŒ â†’ ë¶„ë‹¹ 1500íšŒ (ì¶©ë¶„í•¨!)
- ì›” 150ë§Œ í† í° (README ì•½ 3000ê°œ ìƒì„± ê°€ëŠ¥)

### 2-B. Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ë¡œì»¬ ì‹¤í–‰)

```bash
# ì½”ë“œ ë¬¸ì„œí™”ì— ìµœì í™”ëœ ëª¨ë¸ (ì¶”ì²œ!)
ollama pull qwen2.5-coder:7b

# ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸
ollama pull deepseek-r1:8b    # ì¶”ë¡  ëŠ¥ë ¥ ë›°ì–´ë‚¨
ollama pull qwen2.5:7b         # ë²”ìš© ìµœì‹ 
ollama pull gemma3:12b         # Google ìµœì‹ 
ollama pull llama3.1:8b        # Llama ìµœì‹ 
```

### 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 4. ì‹¤í–‰

```bash
# í˜„ì¬ ë””ë ‰í† ë¦¬ ë¶„ì„
python main.py

# íŠ¹ì • í”„ë¡œì íŠ¸ ë¶„ì„
python main.py C:\path\to\your\project

# ìƒ˜í”Œ í”„ë¡œì íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
python main.py examples/sample_project
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
readme-generator/
â”œâ”€â”€ main.py              # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ generator.py         # README ìƒì„± ë¡œì§
â”œâ”€â”€ file_analyzer.py     # íŒŒì¼ ë¶„ì„ ìœ í‹¸
â”œâ”€â”€ requirements.txt     # ì˜ì¡´ì„±
â””â”€â”€ examples/           # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ
    â””â”€â”€ sample_project/
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- í”„ë¡œì íŠ¸ êµ¬ì¡° ìë™ ë¶„ì„
- í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ìë™ ê°ì§€
- AI ê¸°ë°˜ í”„ë¡œì íŠ¸ ì„¤ëª… ìƒì„±
- ì„¤ì¹˜ ë°©ë²• ë° ì‚¬ìš©ë²• ìë™ ìƒì„±
- ì—¬ëŸ¬ AI ëª¨ë¸ ì„ íƒ ê°€ëŠ¥

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

- Python 3.x
- LangChain
- Ollama (ë¡œì»¬ LLM)

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

```bash
$ python main.py

============================================================
               ğŸ“ README Auto Generator
============================================================

ğŸ“‚ Enter the project path to analyze:
   (Press Enter to use current directory)

> examples/sample_project

âœ“ Project path: C:\Users\...\sample_project

ğŸ¤– Select AI Model:
   1. llama2      - General purpose (default)
   2. codellama   - Optimized for code
   3. mistral     - Faster, good quality
   4. llama3.2    - Latest Llama model

> Select (1-4, default=1): 2

âœ“ Using model: codellama

------------------------------------------------------------
ğŸ” Analyzing project...
ğŸ“Š Detected languages: Python
ğŸ“ Found 1 important files
ğŸ’» Found 1 code files

ğŸ¤– Generating README with AI...
â³ This may take a minute...

âœ… README generated successfully!
ğŸ“„ Location: C:\...\sample_project\README.md
```

## ğŸ“š ì§€ì›í•˜ëŠ” ì–¸ì–´/í”„ë ˆì„ì›Œí¬

- Python (requirements.txt, setup.py, pyproject.toml)
- JavaScript/Node.js (package.json)
- Java (pom.xml)
- Go (go.mod)
- Rust (Cargo.toml)
- Ruby (Gemfile)
- PHP (composer.json)
- ê·¸ ì™¸ ë‹¤ì–‘í•œ ì–¸ì–´

## âš™ï¸ ì„¤ì • ì˜µì…˜

### ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ (2025ë…„ ì¶”ì²œ)

**ğŸŒŸ Google Gemini (ë¬´ë£Œ API):**
- `gemini-2.0-flash` - ğŸ”¥ 2025 ìµœì‹ ! ê°€ì¥ ë¹ ë¥´ê³  ê°•ë ¥ (ì¶”ì²œ!)
- `gemini-1.5-flash` - âš¡ ë§¤ìš° ë¹ ë¦„
- `gemini-1.5-pro` - ğŸ§  GPT-4 ìˆ˜ì¤€

**Ollama ë¡œì»¬ ëª¨ë¸:**

ìµœì‹  ì¶”ì²œ:
- `qwen2.5-coder:7b` - ğŸ”¥ ì½”ë“œ íŠ¹í™” ìµœê³  ì„±ëŠ¥ (8.2M pulls)
- `deepseek-r1:8b` - ğŸ§  ì¶”ë¡  ëŠ¥ë ¥, OpenAI o1ê¸‰ (70M pulls)
- `qwen2.5:7b` - âš¡ ë²”ìš© ìµœì‹ , ë¹ ë¥´ê³  ì •í™• (16M pulls)
- `gemma3:12b` - ğŸ¯ Google ìµœì‹ , ë‹¨ì¼ GPU ìµœì  (24M pulls)

ì½”ë”© íŠ¹í™”:
- `qwen2.5-coder` - ì½”ë“œ ìƒì„±/ë¶„ì„ ìµœê³ 
- `deepseek-coder-v2` - GPT4-Turbo ìˆ˜ì¤€
- `codellama` - Meta ì½”ë“œ ëª¨ë¸

í•œêµ­ì–´:
- `EEVE-Korean-10.8B` - í•œêµ­ì–´ íŠ¹í™”
- `Llama-3-KoEn-8B` - í•œì˜ ì´ì¤‘ì–¸ì–´

### ë¶„ì„ ì œì™¸ ë””ë ‰í† ë¦¬

ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ìŒ ë””ë ‰í† ë¦¬ëŠ” ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤:
- `.git`, `node_modules`, `__pycache__`
- `venv`, `.venv`, `env`
- `dist`, `build`

## ğŸ› ë¬¸ì œ í•´ê²°

### Ollama ì—°ê²° ì˜¤ë¥˜

```bash
# Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
ollama list

# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve
```

### ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# ì‚¬ìš©í•˜ë ¤ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama2
ollama pull codellama
```

### í•œê¸€ ì¸ì½”ë”© ì˜¤ë¥˜

- íŒŒì¼ì€ UTF-8ë¡œ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤
- ë¬¸ì œê°€ ì§€ì†ë˜ë©´ `errors='ignore'` ì˜µì…˜ì´ ì ìš©ë©ë‹ˆë‹¤

## ğŸ”® í–¥í›„ ê³„íš

- [ ] ì›¹ UI ì¶”ê°€ (Streamlit/Gradio)
- [ ] GitHub Actions í†µí•©
- [ ] ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì§€ì›
- [ ] ë‹¤êµ­ì–´ README ìƒì„±
- [ ] ë°°ì§€(Badges) ìë™ ìƒì„± ê°œì„ 
- [ ] ìŠ¤í¬ë¦°ìƒ· ìë™ ê°ì§€ ë° ì‚½ì…

## ğŸ“„ License

MIT License

## ğŸ¤ Contributing

ê¸°ì—¬ëŠ” ì–¸ì œë‚˜ í™˜ì˜í•©ë‹ˆë‹¤!

1. Fork the Project
2. Create your Feature Branch
3. Commit your Changes
4. Push to the Branch
5. Open a Pull Request

---

Made with â¤ï¸ using Ollama and LangChain
